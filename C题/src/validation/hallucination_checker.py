"""
@redcell Agent - Hallucination Attack Module
============================================

Deep integration with @redcell's Six-Dimension Attack Protocol.
Implements SelfCheckGPT methodology for automated paper verification.

Attack Dimensions:
1. assumption_attack  - å‡è®¾æ”»å‡»
2. model_attack       - æ¨¡å‹æ”»å‡»
3. data_attack        - æ•°æ®æ”»å‡»
4. result_attack      - ç»“æœæ”»å‡»
5. presentation_attack - è¡¨è¾¾æ”»å‡»
6. format_attack      - æ ¼å¼æ”»å‡»

O-Award Compliance:
- All statistical outputs verified against code execution
- Assumption-Justification pairing enforced
- Causal language hedging checked
"""

import re
import json
from typing import List, Dict, Tuple, Optional, Any
from dataclasses import dataclass, field, asdict
from enum import Enum
from datetime import datetime
import os


# ==================== @redcell Severity Classification ====================

class AttackSeverity(Enum):
    """@redcell severity levels - aligned with agents.md protocol"""
    FATAL = "fatal"       # ğŸš¨ è‡´å‘½: ä¸ä¿®å¤ç›´æ¥å‡ºå±€
    CRITICAL = "critical" # âš ï¸ ä¸¥é‡: å¯èƒ½å¯¼è‡´é™çº§
    MAJOR = "major"       # ğŸ“ ä¸€èˆ¬: å½±å“è¯„åˆ†
    MINOR = "minor"       # ğŸ’¡ è½»å¾®: é”¦ä¸Šæ·»èŠ±
    PASSED = "passed"     # âœ… é€šè¿‡: éªŒè¯æˆåŠŸ


class AttackDimension(Enum):
    """@redcell six attack dimensions"""
    ASSUMPTION = "assumption_attack"      # å‡è®¾æ”»å‡»
    MODEL = "model_attack"                # æ¨¡å‹æ”»å‡»
    DATA = "data_attack"                  # æ•°æ®æ”»å‡»
    RESULT = "result_attack"              # ç»“æœæ”»å‡»
    PRESENTATION = "presentation_attack"  # è¡¨è¾¾æ”»å‡»
    FORMAT = "format_attack"              # æ ¼å¼æ”»å‡»


# ==================== Attack Finding Data Structures ====================

@dataclass
class AttackFinding:
    """Single attack finding - @redcell protocol compliant"""
    dimension: AttackDimension
    severity: AttackSeverity
    issue: str
    evidence: str
    impact: str
    recommendation: str
    action_required: str
    priority: str  # high, medium, low
    location: str = ""  # section/line in paper
    hallucination_score: float = 0.0  # 0.0 = factual, 1.0 = hallucinated


@dataclass
class RedCellFeedback:
    """
    @redcell â†’ @executor/@strategist feedback schema
    Matches agents.md JSON schema for structured communication
    """
    message_type: str = "RedCellFeedback"
    task_id: str = ""
    review_id: str = ""
    timestamp: str = ""
    target_agent: str = "@executor"
    attack_dimensions: List[Dict] = field(default_factory=list)
    overall_assessment: Dict = field(default_factory=dict)
    action_items: List[Dict] = field(default_factory=list)
    approval_status: str = "conditional"  # conditional | approved | rejected
    approval_conditions: List[str] = field(default_factory=list)
    
    def to_json(self) -> str:
        return json.dumps(asdict(self), indent=2, ensure_ascii=False)


# ==================== @redcell Hallucination Checker ====================

class RedCellHallucinationChecker:
    """
    @redcell Agent - Six-Dimension Hallucination Attack System
    
    Deeply integrated with agents.md protocol for:
    1. assumption_attack  - æ£€æŸ¥å‡è®¾æ˜¯å¦æœ‰Justificationé…å¯¹
    2. model_attack       - æ£€æŸ¥æ¨¡å‹é€‰æ‹©ç†ç”±
    3. data_attack        - æ£€æŸ¥æ•°æ®æ¥æºå’Œæ³„éœ²
    4. result_attack      - æ£€æŸ¥ç»Ÿè®¡ç»“æœæ˜¯å¦ä»£ç æ´¾ç”Ÿ
    5. presentation_attack - æ£€æŸ¥å› æœè¯­è¨€å’Œé€»è¾‘é“¾
    6. format_attack      - æ£€æŸ¥é¡µæ•°/èº«ä»½ä¿¡æ¯/å¼•ç”¨æ ¼å¼
    """
    
    def __init__(self, paper_path: str, code_outputs_path: str, 
                 statistical_tests_path: str = None):
        """
        Args:
            paper_path: Path to paper markdown file
            code_outputs_path: Path to code execution outputs (ground truth)
            statistical_tests_path: Path to statistical_tests_results.txt
        """
        self.paper_path = paper_path
        self.code_outputs_path = code_outputs_path
        self.statistical_tests_path = statistical_tests_path
        self.paper_content = self._load_file(paper_path)
        self.code_outputs = self._load_file(code_outputs_path)
        self.statistical_results = self._load_file(statistical_tests_path) if statistical_tests_path else ""
        
        # Ground truth: all verified numbers from code
        self.verified_numbers = self._extract_verified_numbers()
        
        # Findings storage
        self.findings: List[AttackFinding] = []
        
    def _load_file(self, path: str) -> str:
        """Load file content safely"""
        if not path or not os.path.exists(path):
            return ""
        with open(path, 'r', encoding='utf-8') as f:
            return f.read()
    
    def _extract_verified_numbers(self) -> set:
        """Extract all numbers from code outputs as verified ground truth"""
        all_outputs = self.code_outputs + self.statistical_results
        numbers = re.findall(r'\b\d+\.?\d*\b', all_outputs)
        return set(numbers)

    # ==================== Dimension 1: Assumption Attack ====================
    
    def attack_assumptions(self) -> List[AttackFinding]:
        """
        @redcell assumption_attack
        Checks:
        - æ¯ä¸ªå‡è®¾æ˜¯å¦æœ‰Justificationé…å¯¹
        - Justificationæ˜¯å¦æœ‰å®è¯æ”¯æ’‘
        """
        findings = []
        
        # Extract assumptions (A1, A2, etc.)
        assumption_pattern = r'\*\*A(\d+)[^*]*\*\*[:\s]*([^*]+?)(?=\*\*|\n\n|$)'
        assumptions = re.findall(assumption_pattern, self.paper_content, re.DOTALL)
        
        for a_num, a_content in assumptions:
            # Check for Justification
            has_justification = 'justification' in a_content.lower() or \
                               '*justification*' in a_content.lower()
            
            if not has_justification:
                findings.append(AttackFinding(
                    dimension=AttackDimension.ASSUMPTION,
                    severity=AttackSeverity.CRITICAL,
                    issue=f"å‡è®¾ A{a_num} ç¼ºå°‘ Justification é…å¯¹",
                    evidence=f"A{a_num}: {a_content[:100]}...",
                    impact="è¯„å§”å¯èƒ½è´¨ç–‘å‡è®¾åˆç†æ€§",
                    recommendation="æ·»åŠ  *Justification:* è¯´æ˜å‡è®¾çš„å®è¯ä¾æ®",
                    action_required="@executor è¡¥å……å‡è®¾è®ºè¯",
                    priority="high",
                    hallucination_score=0.7
                ))
            else:
                findings.append(AttackFinding(
                    dimension=AttackDimension.ASSUMPTION,
                    severity=AttackSeverity.PASSED,
                    issue=f"å‡è®¾ A{a_num} å·²æœ‰ Justification",
                    evidence="Assumption-Justification pairing verified",
                    impact="æ— ",
                    recommendation="âœ“ é€šè¿‡",
                    action_required="æ— ",
                    priority="low",
                    hallucination_score=0.0
                ))
        
        return findings

    # ==================== Dimension 2: Model Attack ====================
    
    def attack_model(self) -> List[AttackFinding]:
        """
        @redcell model_attack
        Checks:
        - æ¨¡å‹é€‰æ‹©æ˜¯å¦æœ‰ç†ç”±
        - æ˜¯å¦æœ‰æ›´ç®€å•çš„æ›¿ä»£æ–¹æ¡ˆ
        """
        findings = []
        
        # Check for model comparison table
        has_comparison = 'Model Performance Comparison' in self.paper_content or \
                        'Individual Model vs Ensemble' in self.paper_content
        
        if not has_comparison:
            findings.append(AttackFinding(
                dimension=AttackDimension.MODEL,
                severity=AttackSeverity.MAJOR,
                issue="ç¼ºå°‘æ¨¡å‹å¯¹æ¯”è¡¨",
                evidence="æœªæ‰¾åˆ° Model Performance Comparison è¡¨æ ¼",
                impact="æ— æ³•è¯æ˜é›†æˆæ¨¡å‹ä¼˜äºå•æ¨¡å‹",
                recommendation="æ·»åŠ å„æ¨¡å‹ RÂ²/RMSE/MAE å¯¹æ¯”è¡¨",
                action_required="@executor è¡¥å……æ¨¡å‹å¯¹æ¯”",
                priority="medium",
                hallucination_score=0.5
            ))
        else:
            findings.append(AttackFinding(
                dimension=AttackDimension.MODEL,
                severity=AttackSeverity.PASSED,
                issue="æ¨¡å‹å¯¹æ¯”è¡¨å­˜åœ¨",
                evidence="Found model comparison table",
                impact="æ— ",
                recommendation="âœ“ é€šè¿‡",
                action_required="æ— ",
                priority="low",
                hallucination_score=0.0
            ))
        
        return findings

    # ==================== Dimension 3: Data Attack ====================
    
    def attack_data(self) -> List[AttackFinding]:
        """
        @redcell data_attack
        Checks:
        - æ•°æ®æ¥æºæ˜¯å¦è¯´æ˜
        - æ˜¯å¦å­˜åœ¨æ•°æ®æ³„éœ²
        """
        findings = []
        
        # Check for data source citation
        has_source = 'COMAP' in self.paper_content or 'IOC' in self.paper_content
        
        if not has_source:
            findings.append(AttackFinding(
                dimension=AttackDimension.DATA,
                severity=AttackSeverity.CRITICAL,
                issue="æ•°æ®æ¥æºæœªè¯´æ˜",
                evidence="æœªæ‰¾åˆ° COMAP æˆ– IOC æ•°æ®æºå¼•ç”¨",
                impact="è¯„å§”å¯èƒ½è´¨ç–‘æ•°æ®å¯ä¿¡åº¦",
                recommendation="æ˜ç¡®æ ‡æ³¨æ•°æ®æ¥æº",
                action_required="@executor è¡¥å……æ•°æ®æ¥æºè¯´æ˜",
                priority="high",
                hallucination_score=0.8
            ))
        
        # Check for data leakage warning
        mentions_leakage = 'leakage' in self.paper_content.lower() or \
                          'temporal split' in self.paper_content.lower()
        
        if not mentions_leakage:
            findings.append(AttackFinding(
                dimension=AttackDimension.DATA,
                severity=AttackSeverity.MAJOR,
                issue="æœªè®¨è®ºæ•°æ®æ³„éœ²é˜²æŠ¤",
                evidence="æœªæ‰¾åˆ° leakage æˆ– temporal split ç›¸å…³è®¨è®º",
                impact="æ—¶åºé¢„æµ‹å¿…é¡»è¯´æ˜å¦‚ä½•é¿å…æœªæ¥ä¿¡æ¯æ³„éœ²",
                recommendation="åœ¨ Train/Test Split éƒ¨åˆ†è¯´æ˜æ—¶åºåˆ†å‰²æ–¹æ³•",
                action_required="@executor è¡¥å……æ—¶åºéªŒè¯è¯´æ˜",
                priority="medium",
                hallucination_score=0.6
            ))
        
        return findings

    # ==================== Dimension 4: Result Attack ====================
    
    def attack_results(self) -> List[AttackFinding]:
        """
        @redcell result_attack - CORE SelfCheckGPT Integration
        Checks:
        - æ¯ä¸ªç»Ÿè®¡æ•°å€¼æ˜¯å¦åœ¨ä»£ç è¾“å‡ºä¸­æ‰¾åˆ°
        - ç½®ä¿¡åŒºé—´æ˜¯å¦åˆç†
        """
        findings = []
        
        # Extract all statistical claims
        stat_patterns = [
            (r'R[Â²2]\s*[=â‰ˆ]\s*([\d.]+)', 'RÂ²'),
            (r'RMSE\s*[=â‰ˆ]\s*([\d.]+)', 'RMSE'),
            (r'MAE\s*[=â‰ˆ]\s*([\d.]+)', 'MAE'),
            (r'p\s*[<>=]\s*([\d.]+)', 'p-value'),
            (r'F-statistic\s*[=â‰ˆ]\s*([\d.]+)', 'F-statistic'),
            (r't-statistic\s*[=â‰ˆ]\s*([\d.]+)', 't-statistic'),
            (r"Cohen's\s*d\s*[=â‰ˆ]\s*([\d.]+)", "Cohen's d"),
            (r'VIF\s*[=â‰ˆ]\s*([\d.]+)', 'VIF'),
        ]
        
        verified_count = 0
        unverified_count = 0
        
        for pattern, stat_name in stat_patterns:
            matches = re.findall(pattern, self.paper_content, re.IGNORECASE)
            for value in matches:
                if value in self.verified_numbers:
                    verified_count += 1
                else:
                    unverified_count += 1
                    findings.append(AttackFinding(
                        dimension=AttackDimension.RESULT,
                        severity=AttackSeverity.CRITICAL,
                        issue=f"{stat_name}={value} æœªåœ¨ä»£ç è¾“å‡ºä¸­æ‰¾åˆ°",
                        evidence=f"æœç´¢ '{value}' äº code_outputs å’Œ statistical_tests å‡æœªå‘½ä¸­",
                        impact="è¯„å§”å¯èƒ½è´¨ç–‘æ•°æ®çœŸå®æ€§",
                        recommendation=f"ç¡®ä¿ {stat_name} æ¥è‡ªä»£ç æ‰§è¡Œç»“æœ",
                        action_required="@executor éªŒè¯æˆ–ä¿®æ­£è¯¥æ•°å€¼",
                        priority="high",
                        hallucination_score=0.9
                    ))
        
        # Summary finding
        if verified_count > 0:
            findings.append(AttackFinding(
                dimension=AttackDimension.RESULT,
                severity=AttackSeverity.PASSED,
                issue=f"{verified_count} ä¸ªç»Ÿè®¡æ•°å€¼å·²éªŒè¯",
                evidence="Numbers found in code output",
                impact="æ— ",
                recommendation="âœ“ ç»Ÿè®¡æ•°å€¼å¯æº¯æº",
                action_required="æ— ",
                priority="low",
                hallucination_score=0.0
            ))
        
        return findings

    # ==================== Dimension 5: Presentation Attack ====================
    
    def attack_presentation(self) -> List[AttackFinding]:
        """
        @redcell presentation_attack
        Checks:
        - å› æœè¯­è¨€æ˜¯å¦æœ‰hedging
        - å›¾è¡¨æ˜¯å¦è¢«å¼•ç”¨
        """
        findings = []
        
        # Check causal claims for hedging
        causal_markers = ['cause', 'result in', 'lead to', 'because', 'therefore']
        hedging_terms = ['may', 'might', 'could', 'suggests', 'indicates', 'associated']
        
        for marker in causal_markers:
            if marker in self.paper_content.lower():
                # Check if hedging is nearby
                pattern = rf'.{{0,100}}{marker}.{{0,100}}'
                matches = re.findall(pattern, self.paper_content, re.IGNORECASE)
                for match in matches:
                    has_hedging = any(h in match.lower() for h in hedging_terms)
                    if not has_hedging:
                        findings.append(AttackFinding(
                            dimension=AttackDimension.PRESENTATION,
                            severity=AttackSeverity.MAJOR,
                            issue=f"å› æœè¯­è¨€ '{marker}' ç¼ºå°‘hedging",
                            evidence=f"...{match[:80]}...",
                            impact="è¿‡åº¦å› æœæ¨æ–­ï¼Œç›¸å…³â‰ å› æœ",
                            recommendation="æ·»åŠ  'may', 'suggests' ç­‰hedgingè¯­è¨€",
                            action_required="@executor ä¿®æ”¹å› æœè¡¨è¿°",
                            priority="medium",
                            hallucination_score=0.5
                        ))
                        break  # One finding per marker
        
        # Check Figure/Table references
        figures = re.findall(r'Figure\s*(\d+)', self.paper_content)
        tables = re.findall(r'Table\s*(\d+)', self.paper_content)
        
        for fig_num in set(figures):
            if figures.count(fig_num) < 2:  # Defined but never referenced
                findings.append(AttackFinding(
                    dimension=AttackDimension.PRESENTATION,
                    severity=AttackSeverity.MINOR,
                    issue=f"Figure {fig_num} å¯èƒ½æœªè¢«å……åˆ†å¼•ç”¨",
                    evidence=f"Figure {fig_num} appears only {figures.count(fig_num)} time(s)",
                    impact="è¯„å§”å¯èƒ½è®¤ä¸ºå›¾è¡¨æ²¡æœ‰è®¨è®º",
                    recommendation="åœ¨æ­£æ–‡ä¸­å¼•ç”¨å¹¶è®¨è®ºè¯¥å›¾è¡¨",
                    action_required="@executor è¡¥å……å›¾è¡¨å¼•ç”¨",
                    priority="low",
                    hallucination_score=0.2
                ))
        
        return findings

    # ==================== Dimension 6: Format Attack ====================
    
    def attack_format(self) -> List[AttackFinding]:
        """
        @redcell format_attack
        Checks:
        - é¡µæ•°æ˜¯å¦â‰¤ 25
        - æ˜¯å¦æœ‰èº«ä»½ä¿¡æ¯æ³„éœ²
        - Summary Sheet æ˜¯å¦å­˜åœ¨
        """
        findings = []
        
        # Check for Summary Sheet
        has_summary = 'Summary' in self.paper_content[:500] or \
                     'æ‘˜è¦' in self.paper_content[:500]
        
        if not has_summary:
            findings.append(AttackFinding(
                dimension=AttackDimension.FORMAT,
                severity=AttackSeverity.FATAL,
                issue="ç¼ºå°‘ Summary Sheet",
                evidence="è®ºæ–‡å¼€å¤´500å­—ç¬¦å†…æœªæ‰¾åˆ° Summary",
                impact="ç›´æ¥å‡ºå±€ï¼MCMå¼ºåˆ¶è¦æ±‚",
                recommendation="åœ¨è®ºæ–‡ç¬¬ä¸€é¡µæ·»åŠ  Summary Sheet",
                action_required="@executor ç«‹å³æ·»åŠ  Summary",
                priority="high",
                hallucination_score=1.0
            ))
        
        # Check for identity leakage
        identity_patterns = [
            r'\b[A-Za-z]+\s+University\b',
            r'\b[A-Za-z]+\s+College\b',
            r'@[a-zA-Z0-9]+\.edu',
            r'Team\s*#?\d+',
        ]
        
        for pattern in identity_patterns:
            if re.search(pattern, self.paper_content):
                findings.append(AttackFinding(
                    dimension=AttackDimension.FORMAT,
                    severity=AttackSeverity.FATAL,
                    issue="æ£€æµ‹åˆ°æ½œåœ¨èº«ä»½ä¿¡æ¯æ³„éœ²",
                    evidence=f"åŒ¹é…åˆ°æ¨¡å¼: {pattern}",
                    impact="ç›´æ¥å‡ºå±€ï¼ç»å¯¹ç¦æ­¢",
                    recommendation="åˆ é™¤æ‰€æœ‰å­¦æ ¡/å§“å/é‚®ç®±ä¿¡æ¯",
                    action_required="@executor ç«‹å³åˆ é™¤èº«ä»½ä¿¡æ¯",
                    priority="high",
                    hallucination_score=1.0
                ))
        
        return findings

    # ==================== Main Attack Pipeline ====================
    
    def run_full_attack(self) -> RedCellFeedback:
        """
        Execute all six attack dimensions.
        Returns structured @redcell feedback.
        """
        # Run all attacks
        all_findings = []
        all_findings.extend(self.attack_assumptions())
        all_findings.extend(self.attack_model())
        all_findings.extend(self.attack_data())
        all_findings.extend(self.attack_results())
        all_findings.extend(self.attack_presentation())
        all_findings.extend(self.attack_format())
        
        self.findings = all_findings
        
        # Build feedback structure
        feedback = RedCellFeedback(
            task_id=f"mcm_{datetime.now().strftime('%Y%m%d')}",
            review_id=f"review_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            timestamp=datetime.now().isoformat(),
            target_agent="@executor"
        )
        
        # Group findings by dimension
        dimension_groups = {}
        for finding in all_findings:
            dim = finding.dimension.value
            if dim not in dimension_groups:
                dimension_groups[dim] = []
            dimension_groups[dim].append({
                "severity": finding.severity.value,
                "issue": finding.issue,
                "evidence": finding.evidence,
                "impact": finding.impact,
                "recommendation": finding.recommendation,
                "action_required": finding.action_required,
                "priority": finding.priority,
                "hallucination_score": finding.hallucination_score
            })
        
        feedback.attack_dimensions = [
            {"dimension": dim, "findings": findings}
            for dim, findings in dimension_groups.items()
        ]
        
        # Calculate overall assessment
        fatal_count = sum(1 for f in all_findings if f.severity == AttackSeverity.FATAL)
        critical_count = sum(1 for f in all_findings if f.severity == AttackSeverity.CRITICAL)
        major_count = sum(1 for f in all_findings if f.severity == AttackSeverity.MAJOR)
        passed_count = sum(1 for f in all_findings if f.severity == AttackSeverity.PASSED)
        
        avg_score = sum(f.hallucination_score for f in all_findings) / len(all_findings) if all_findings else 0
        
        feedback.overall_assessment = {
            "quality_score": round((1 - avg_score) * 10, 1),
            "quality_breakdown": {
                "fatal_issues": fatal_count,
                "critical_issues": critical_count,
                "major_issues": major_count,
                "passed_checks": passed_count
            },
            "o_award_readiness": f"{int((1 - avg_score) * 100)}%",
            "blocking_issues": fatal_count > 0,
            "average_hallucination_score": round(avg_score, 3)
        }
        
        # Generate action items
        action_id = 1
        for finding in all_findings:
            if finding.severity in [AttackSeverity.FATAL, AttackSeverity.CRITICAL]:
                feedback.action_items.append({
                    "id": f"AI_{action_id:03d}",
                    "assignee": "@executor",
                    "priority": finding.priority,
                    "task": finding.recommendation,
                    "deadline": "ASAP" if finding.severity == AttackSeverity.FATAL else "Before submission"
                })
                action_id += 1
        
        # Determine approval status
        if fatal_count > 0:
            feedback.approval_status = "rejected"
            feedback.approval_conditions = ["å¿…é¡»ä¿®å¤æ‰€æœ‰ FATAL é—®é¢˜æ‰èƒ½æäº¤"]
        elif critical_count > 0:
            feedback.approval_status = "conditional"
            feedback.approval_conditions = [f"ä¿®å¤ {critical_count} ä¸ª CRITICAL é—®é¢˜åå¯æäº¤"]
        else:
            feedback.approval_status = "approved"
            feedback.approval_conditions = ["âœ“ é€šè¿‡æ‰€æœ‰å…³é”®æ£€æŸ¥"]
        
        return feedback

    def generate_markdown_report(self) -> str:
        """
        Generate human-readable @redcell attack report.
        """
        feedback = self.run_full_attack()
        
        report = []
        report.append("# ğŸš¨ @redcell Hallucination Attack Report")
        report.append(f"\n**Review ID**: {feedback.review_id}")
        report.append(f"**Timestamp**: {feedback.timestamp}")
        report.append(f"**Paper**: {self.paper_path}")
        report.append("")
        
        # Overall Assessment
        assessment = feedback.overall_assessment
        report.append("## ğŸ¯ Overall Assessment")
        report.append("")
        report.append("| Metric | Value |")
        report.append("|--------|-------|")
        report.append(f"| Quality Score | {assessment['quality_score']}/10 |")
        report.append(f"| O-Award Readiness | {assessment['o_award_readiness']} |")
        report.append(f"| Avg Hallucination Score | {assessment['average_hallucination_score']} |")
        report.append(f"| Approval Status | **{feedback.approval_status.upper()}** |")
        report.append("")
        
        # Issue Summary
        breakdown = assessment['quality_breakdown']
        report.append("## ğŸ“Š Issue Summary")
        report.append("")
        report.append("| Severity | Count |")
        report.append("|----------|-------|")
        report.append(f"| ğŸš¨ Fatal | {breakdown['fatal_issues']} |")
        report.append(f"| âš ï¸ Critical | {breakdown['critical_issues']} |")
        report.append(f"| ğŸ“ Major | {breakdown['major_issues']} |")
        report.append(f"| âœ… Passed | {breakdown['passed_checks']} |")
        report.append("")
        
        # Dimension Details
        report.append("## ğŸ” Attack Dimension Details")
        for dim_group in feedback.attack_dimensions:
            dim_name = dim_group['dimension'].replace('_', ' ').title()
            report.append(f"\n### {dim_name}")
            report.append("")
            report.append("| Issue | Severity | Score | Recommendation |")
            report.append("|-------|----------|-------|----------------|")
            for finding in dim_group['findings']:
                report.append(f"| {finding['issue'][:40]}... | {finding['severity']} | {finding['hallucination_score']} | {finding['recommendation'][:30]}... |")
        
        # Action Items
        if feedback.action_items:
            report.append("\n## ğŸ“ Action Items")
            report.append("")
            report.append("| ID | Priority | Task | Deadline |")
            report.append("|-----|----------|------|----------|")
            for item in feedback.action_items:
                report.append(f"| {item['id']} | {item['priority']} | {item['task'][:40]}... | {item['deadline']} |")
        
        # Approval
        report.append("\n## âœ… Approval Status")
        report.append(f"\n**Status**: `{feedback.approval_status.upper()}`")
        for condition in feedback.approval_conditions:
            report.append(f"- {condition}")
        
        return "\n".join(report)


# ==================== Quick Usage Interface ====================

def run_redcell_attack(paper_path: str, outputs_path: str, 
                       statistical_tests_path: str = None) -> Tuple[RedCellFeedback, str]:
    """
    @redcell Agent Entry Point - Run full hallucination attack.
    
    Usage:
        feedback, report = run_redcell_attack(
            "paper/mcm_2025_c_paper.md",
            "output/complete_mcm_analysis_report.txt",
            "output/statistical_tests_results.txt"
        )
        print(report)  # Human-readable Markdown
        print(feedback.to_json())  # Structured JSON for agent communication
    
    Returns:
        Tuple[RedCellFeedback, str]: Structured feedback + Markdown report
    """
    checker = RedCellHallucinationChecker(
        paper_path=paper_path,
        code_outputs_path=outputs_path,
        statistical_tests_path=statistical_tests_path
    )
    feedback = checker.run_full_attack()
    report = checker.generate_markdown_report()
    return feedback, report


# Backward compatibility alias
def check_paper_hallucinations(paper_path: str, outputs_path: str) -> str:
    """Legacy function for backward compatibility"""
    _, report = run_redcell_attack(paper_path, outputs_path)
    return report


if __name__ == "__main__":
    # Example: Run @redcell attack on Cé¢˜ paper
    import sys
    
    base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    paper_path = os.path.join(base_dir, "paper", "mcm_2025_c_paper.md")
    outputs_path = os.path.join(base_dir, "output", "complete_mcm_analysis_report.txt")
    stats_path = os.path.join(base_dir, "output", "statistical_tests_results.txt")
    
    print("\n" + "="*60)
    print("@redcell Agent - Six-Dimension Hallucination Attack")
    print("="*60 + "\n")
    
    if os.path.exists(paper_path):
        feedback, report = run_redcell_attack(paper_path, outputs_path, stats_path)
        print(report)
        print("\n" + "="*60)
        print("Structured Feedback (JSON for Agent Communication):")
        print("="*60)
        print(feedback.to_json())
    else:
        print(f"Paper not found: {paper_path}")
        sys.exit(1)
